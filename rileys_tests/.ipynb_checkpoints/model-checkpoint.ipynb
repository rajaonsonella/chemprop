{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE : cuda:0\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Union, Dict\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "import rdkit\n",
    "import rdkit.Chem\n",
    "import rdkit.Chem.AllChem as Chem\n",
    "import rdkit.Chem.rdFingerprintGenerator as rdFP\n",
    "\n",
    "try:\n",
    "    import umap\n",
    "except:\n",
    "    !pip install umap-learn\n",
    "    import umap\n",
    "from rdkit import Chem\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import deepchem as dc\n",
    "import chemprop\n",
    "\n",
    "from chemprop.models import MPN\n",
    "from chemprop.args import TrainArgs\n",
    "from chemprop.data import get_data_from_deepchem\n",
    "from chemprop.features import BatchMolGraph\n",
    "from chemprop.nn_utils import get_activation_function, initialize_weights\n",
    "\n",
    "# set device \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'DEVICE : {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some data from DeepChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task, data, ids = dc.molnet.load_delaney(splitter=None)\n",
    "df = data[0].to_dataframe()\n",
    "df = df.rename(columns={'ids': 'smiles'})\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = df['smiles'].tolist()\n",
    "y      = df['y'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/test target/context\n",
    "smiles_context = smiles[:500]\n",
    "smiles_target = smiles[500:]\n",
    "\n",
    "y_context = y[:500]\n",
    "y_target = y[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _TESTING_ Run the standalone MPN from chemprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data from deepchem\n",
    "context_data = get_data_from_deepchem(smiles_array=smiles_context, targets_array=y_context)\n",
    "target_data  = get_data_from_deepchem(smiles_array=smiles_target, targets_array=y_target)\n",
    "context_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the batchgraph objects for context and target sets \n",
    "context_graph = context_data.batch_graph()\n",
    "context_y     = context_data.targets()\n",
    "target_graph  = target_data.batch_graph()\n",
    "target_y      = context_data.targets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training args\n",
    "args = TrainArgs()\n",
    "args.mpn_shared = True\n",
    "args.dataset_type = 'regression'\n",
    "args.process_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the MPN model\n",
    "model_mpn = MPN(args)\n",
    "model_mpn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the embeddings for the context set (# samples, 300)\n",
    "preds = model_mpn(context_graph)\n",
    "preds_numpy = preds.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play around with the data loading\n",
    "task, data, ids = dc.molnet.load_delaney(splitter=None)\n",
    "X = data[0].X        # ECFP fingerprints\n",
    "y = data[0].y        # targets\n",
    "smiles = data[0].ids # smiles\n",
    "\n",
    "print(X.shape, y.shape, len(smiles))\n",
    "\n",
    "dataset = {'smiles': smiles, 'X': X, 'y': y}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put umap over data for visualization\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "y_umap = umap.UMAP(metric='cosine', min_dist=0.65).fit_transform(X)\n",
    "plt.scatter(y_umap[:, 0], y_umap[:, 1], c=y.ravel(), cmap='inferno')\n",
    "cbar = plt.colorbar().set_label('measured log solubility [mol/L]', fontsize=12)\n",
    "\n",
    "\n",
    "plt.savefig('delany_umap.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into tasks --> evenly sized, for now\n",
    "\n",
    "np.random.seed()\n",
    "num_tasks = 15                  # ~ 75 mols per task\n",
    "num_per_task = 75\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "tasks = []\n",
    "\n",
    "for task_ix in range(num_tasks):\n",
    "    \n",
    "    task_smiles = smiles[indices[:num_per_task]]\n",
    "    task_X      = X[indices[:num_per_task], :]\n",
    "    task_y      = y[indices[:num_per_task], :]\n",
    "    \n",
    "    tasks.append({'smiles':task_smiles.tolist(), \n",
    "                  'X':torch.from_numpy(task_X), \n",
    "                  'y':torch.from_numpy(task_y)}\n",
    "            )\n",
    "\n",
    "    indices = np.roll(indices, num_per_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split tasks into training and validation\n",
    "NUM_TRAIN_TASKS = 12\n",
    "NUM_VALID_TASKS = 3\n",
    "\n",
    "\n",
    "train_tasks = tasks[:NUM_TRAIN_TASKS]\n",
    "valid_tasks = tasks[NUM_TRAIN_TASKS:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    \n",
    "    @staticmethod\n",
    "    def r2(true, pred):\n",
    "        return r2_score(true, pred)\n",
    "    @staticmethod\n",
    "    def rmse(true, pred):\n",
    "        return np.sqrt(mean_squared_error(true, pred))\n",
    "    @staticmethod\n",
    "    def mae(true, pred):\n",
    "        return mean_absolute_error(true, pred)\n",
    "    @staticmethod\n",
    "    def pearson(true, pred):\n",
    "        true, pred = np.squeeze(true), np.squeeze(pred)\n",
    "        return pearsonr(true, pred)\n",
    "    @staticmethod\n",
    "    def spearman(true, pred):\n",
    "        true, pred = np.squeeze(true), np.squeeze(pred)\n",
    "        return spearmanr(true, pred)\n",
    "\n",
    "    def compute_metrics(self, true, pred, kinds):\n",
    "        metrics = {}\n",
    "        for kind in kinds:\n",
    "            try:\n",
    "                fn = getattr(self, kind)\n",
    "            except NameError as e:\n",
    "                print(e)\n",
    "            error = fn(true, pred)\n",
    "            metrics[kind] = error\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Testing_ Build the MPCNP model\n",
    "\n",
    "#### Unique modules\n",
    "* MPNN (used for representation learning in the encoder and decoder branch) --> directly from chemprop\n",
    "* MLP (feedforward network used for the encoder and decoder) --> implemented here\n",
    "\n",
    "#### Instances\n",
    "* MPNN (rep learning) \n",
    "* MLP encoder\n",
    "* MLP decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "class MLPEncoder(nn.Module):\n",
    "    ''' Densely connected feed-forward MLP - encoder \n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 params,\n",
    "                 inp_size,\n",
    "                 **kwargs\n",
    "        ):\n",
    "        super(MLPEncoder, self).__init__()\n",
    "        self.params = params\n",
    "        self.inp_size = inp_size\n",
    "        \n",
    "        num_layers = len(self.params['hidden_size'])+1\n",
    "        \n",
    "        layers = []\n",
    "        for hidden_ix, hidden_size in enumerate(self.params['hidden_size']):\n",
    "            if hidden_ix == 0:\n",
    "                layers.append(nn.Linear(inp_size, hidden_size))\n",
    "            else:\n",
    "                layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "        layers.append(nn.Linear(self.params['hidden_size'][-1], self.params['out_size']))\n",
    "        #layers.append(self.params['out_act'])\n",
    "        \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, \n",
    "                mpn_rep_x,\n",
    "                context_y,\n",
    "            ) -> torch.FloatTensor:\n",
    "        ''' forward pass of fully-connected MLP\n",
    "        \n",
    "        Args:\n",
    "            mpn_rep_x : output of mpnn for context_x\n",
    "            context_y : respective context_y values\n",
    "        '''\n",
    "        \n",
    "        # concatenate the mpn_rep_x and context_y\n",
    "        enc_input = torch.cat((mpn_rep_x, context_y), dim=-1) # [batch_size, n_context, inp_size]\n",
    "        batch_size, filter_size = enc_input.shape[0], enc_input.shape[-1]                       \n",
    "        enc_input = enc_input.view(-1, self.inp_size)             # [batch_size * n_context, inp_size]\n",
    "        \n",
    "        enc_out = self.mlp(enc_input.float())                         # [batch_size * n_context, hidden_size]\n",
    "        \n",
    "        enc_out = enc_out.view(batch_size, -1, self.params['out_size']) # [batch_size, n_context, hidden_size]\n",
    "        \n",
    "        rep     = torch.mean(enc_out, 1)                      # [batch_size, hidden_size]\n",
    "        \n",
    "        return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "class MLPDecoder(nn.Module):\n",
    "    ''' Densely connected feed-forward MLP - encoder \n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 params,\n",
    "                 inp_size,\n",
    "                 **kwargs\n",
    "        ):\n",
    "        super(MLPDecoder, self).__init__()\n",
    "        self.params = params\n",
    "        self.inp_size = inp_size\n",
    "        \n",
    "        num_layers = len(self.params['hidden_size'])+1\n",
    "        \n",
    "        layers = []\n",
    "        for hidden_ix, hidden_size in enumerate(self.params['hidden_size']):\n",
    "            if hidden_ix == 0:\n",
    "                layers.append(nn.Linear(inp_size, hidden_size))\n",
    "            else:\n",
    "                layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "        layers.append(nn.Linear(self.params['hidden_size'][-1], self.params['out_size']))\n",
    "        #layers.append(self.params['out_act'])\n",
    "        \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, \n",
    "                mpn_rep_x, \n",
    "                enc_rep,\n",
    "            ) -> torch.FloatTensor:\n",
    "        ''' forward pass of fully-connected MLP\n",
    "        \n",
    "        Args:\n",
    "            mpn_rep_x : output of mpnn for target_x\n",
    "            enc_rep   : representation from encoder\n",
    "        '''\n",
    "\n",
    "        \n",
    "        batch_size = mpn_rep_x.shape[0]\n",
    "        \n",
    "        enc_rep = torch.unsqueeze(enc_rep, dim=1).repeat(1, mpn_rep_x.shape[1], 1)  # inflate inputs\n",
    "        \n",
    "        # filter_size = enc_rep_size + mpn_rep_x_size\n",
    "        dec_input = torch.cat((mpn_rep_x, enc_rep), dim=2)                  # [batch_size, n_target, filter_size]\n",
    "        \n",
    "        dec_input = dec_input.view(-1, self.inp_size)                       # [batch_size*n_target, filter_size]\n",
    "        \n",
    "        dec_out = self.mlp(dec_input.float())                               # [batch_size*n_target, 2*output_size]\n",
    "        \n",
    "        mu, log_sigma = torch.split(dec_out, 1, dim=1)\n",
    "        \n",
    "        # TODO:  last dim is hardcoded - fix this\n",
    "        mu = mu.view(batch_size, -1, 1)                                     # [batch_size, n_target, output_size]\n",
    "        \n",
    "        sigma = 0.1 + 0.9 * nn.Softplus()(log_sigma)\n",
    "        sigma = sigma.view(batch_size, -1, 1)\n",
    "        \n",
    "        dist = [MultivariateNormal(m, torch.diag_embed(s)) for m, s in zip(mu, sigma)]\n",
    "        \n",
    "        return mu, sigma, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPCNP model\n",
    "class MPCNP():\n",
    "    ''' Message-passing conditional neural process model\n",
    "    '''\n",
    "    DEF_ARGS = TrainArgs()\n",
    "    DEF_ARGS.mpn_shared = True\n",
    "    DEF_ARGS.dataset_type = 'regression'\n",
    "    DEF_ARGS.process_args()\n",
    "    \n",
    "    DEF_ENCODER_PARAMS   = {'hidden_size': [100, 100],\n",
    "                            'out_size': 50, \n",
    "                            'hidden_act': lambda y: nn.ReLU(y),\n",
    "                    }\n",
    "    DEF_DECODER_PARAMS   = {'hidden_size': [100, 100],\n",
    "                            'out_size': 2, \n",
    "                            'hidden_act': nn.ReLU(),\n",
    "                    }\n",
    " \n",
    "\n",
    "    def __init__(self,\n",
    "                 args: TrainArgs=None,               # MPNN args\n",
    "                 encoder_params:Dict[str, any]=None,\n",
    "                 decoder_params:Dict[str, any]=None,\n",
    "                 use_mpnn:bool=True, \n",
    "                 learning_rate:float=1e-4,\n",
    "                 batch_size:int=20, \n",
    "                 pred_int:int=25, \n",
    "                 epochs:int=8000, \n",
    "                 x_size:int=300,\n",
    "                 y_size:int=1,\n",
    "                 context_x_scaling:str='same',\n",
    "                 context_y_scaling:str='same', \n",
    "                 target_x_scaling:str='same',\n",
    "                 target_y_scaling:str='same', \n",
    "                 device:str='gpu',\n",
    "                 **kwargs,\n",
    "    ):\n",
    "#        super(MPCNP, self).__init__()\n",
    "        self.use_mpnn = use_mpnn\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.pred_int = pred_int\n",
    "        self.epochs = 8000\n",
    "        self.x_size = x_size           # this should be embedding size in this case\n",
    "        self.y_size = y_size\n",
    "        self.output_size = 2*self.y_size # mean + var for each y dim\n",
    "        self.context_x_scaling = context_x_scaling\n",
    "        self.context_y_scaling = context_y_scaling\n",
    "        self.target_x_scaling = target_x_scaling\n",
    "        self.target_y_scaling = target_y_scaling\n",
    "        \n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f'DEVICE : {self.device}')\n",
    "\n",
    "        self.encoder_params = self._parse_params(\n",
    "                                    encoder_params,\n",
    "                                    self.DEF_ENCODER_PARAMS,\n",
    "                            )\n",
    "        self.decoder_params = self._parse_params(\n",
    "                                    decoder_params, \n",
    "                                    self.DEF_DECODER_PARAMS,\n",
    "                            )\n",
    "        \n",
    "        self._create_encoder()\n",
    "        params_encoder = list(self.encoder.parameters())\n",
    "        self._create_decoder()\n",
    "        params_decoder = list(self.decoder.parameters())\n",
    "        \n",
    "        \n",
    "        if self.use_mpnn:\n",
    "            self.args = args or self.DEF_ARGS\n",
    "            self._create_mpn()\n",
    "            params_mpnn = list(self.mpn.parameters())\n",
    "        else:\n",
    "            params_mpnn = []\n",
    "            \n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(\n",
    "                                    params_mpnn+\n",
    "                                    params_encoder+\n",
    "                                    params_decoder,\n",
    "                                    lr=self.learning_rate,\n",
    "                    )\n",
    "        \n",
    "        self.metrics = Metrics()\n",
    "        \n",
    "    \n",
    "   \n",
    "    def _parse_params(self, user_params, default_params):\n",
    "        if not user_params:\n",
    "            params = default_params\n",
    "        \n",
    "        elif type(user_params)==dict:\n",
    "            params = {}\n",
    "            for key, val in default_params.items():\n",
    "                try:\n",
    "                    params[key] = user_params[key] \n",
    "                except: \n",
    "                    params[key] = val\n",
    "        else:\n",
    "            print('@@\\tUser hyperparams not understood, resorting to default... [WARNING] ')\n",
    "            params = default_params\n",
    "        return params\n",
    "            \n",
    "        \n",
    "    def _create_mpn(self):\n",
    "        self.mpn = MPN(self.args)\n",
    "        self.mpn.to(self.device)\n",
    "    \n",
    "    def _create_encoder(self):\n",
    "        self.encoder = MLPEncoder(self.encoder_params, self.x_size+self.y_size)\n",
    "        self.encoder.to(self.device)\n",
    "        \n",
    "    def _create_decoder(self):\n",
    "        self.decoder = MLPDecoder(self.decoder_params, self.encoder_params['out_size']+self.x_size)\n",
    "        self.decoder.to(self.device)\n",
    "        \n",
    "    def loss_fn(self, dist, target_y):\n",
    "        ''' negative log-likelihood\n",
    "        '''\n",
    "        log_probs = [d.log_prob(target_y[_, ...].float()) for _, d in enumerate(dist)]\n",
    "        return -torch.mean(torch.cat(log_probs, dim=0))\n",
    "\n",
    "        \n",
    "    def train(self,\n",
    "              train_tasks,\n",
    "              valid_tasks, \n",
    "              \n",
    "        ):\n",
    "        ''' train the MPCNP\n",
    "        \n",
    "        Args: \n",
    "        \n",
    "            train_tasks (list): list of training task data\n",
    "            valid_tasks (list): list of validation task data\n",
    "        '''\n",
    "        \n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        all_train_metrics = []\n",
    "        all_valid_metrics = []\n",
    "        \n",
    "        num_train_tasks = len(train_tasks)\n",
    "        num_valid_tasks = len(valid_tasks)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            task_ix = np.random.randint(num_train_tasks)\n",
    "            train_task = train_tasks[task_ix]\n",
    "                \n",
    "            \n",
    "            train_smiles = np.array(train_task['smiles'])\n",
    "            train_x      = train_task['X']\n",
    "            train_y      = train_task['y']\n",
    "            \n",
    "            \n",
    "            num_target  = torch.randint(low=10, high=int(0.8*train_x.shape[0]), size=(1,))\n",
    "            num_context = torch.randint(low=5, high=int(num_target), size=(1,))\n",
    "            \n",
    "            indices = [np.random.permutation(train_x.shape[0])[:num_target] for _ in range(self.batch_size)]\n",
    "            indices_context = [indices[_][:num_context] for _ in range(self.batch_size)]\n",
    "            \n",
    "            train_target_x  = [train_x[indices[_], :] for _ in range(self.batch_size)]\n",
    "            train_target_y  = [train_y[indices[_], :] for _ in range(self.batch_size)]\n",
    "            \n",
    "            train_target_smiles = [train_smiles[indices[_]] for _ in range(self.batch_size)]\n",
    "            \n",
    "            train_context_x = [train_x[indices_context[_], :] for _ in range(self.batch_size)]\n",
    "            train_context_y = [train_y[indices_context[_], :] for _ in range(self.batch_size)]\n",
    "            \n",
    "            train_context_smiles = [train_smiles[indices_context[_]] for _ in range(self.batch_size)]\n",
    "            \n",
    "            if self.use_mpnn:                 \n",
    "                # generate the chemprop data loader thing --> context\n",
    "                context_hs = []\n",
    "                for batch_ix, (batch_smiles, batch_y) in enumerate(zip(train_context_smiles, train_context_y)):\n",
    "                    mol_dataset = get_data_from_deepchem(smiles_array=batch_smiles, targets_array=batch_y)\n",
    "                    graph, y = mol_dataset.batch_graph(), mol_dataset.targets()\n",
    "                    h = self.mpn(graph)\n",
    "                    context_hs.append(h)\n",
    "                train_context_x = torch.stack(context_hs).cuda()\n",
    "                    \n",
    "                # generate the target hs\n",
    "                target_hs = []\n",
    "                for batch_ix, (batch_smiles, batch_y) in enumerate(zip(train_target_smiles, train_target_y)):\n",
    "                    mol_dataset = get_data_from_deepchem(smiles_array=batch_smiles, targets_array=batch_y)\n",
    "                    graph, y = mol_dataset.batch_graph(), mol_dataset.targets()\n",
    "                    h = self.mpn(graph)\n",
    "                    target_hs.append(h)\n",
    "                train_target_x = torch.stack(target_hs).cuda()\n",
    "                \n",
    "            else:\n",
    "                train_target_x  = torch.stack(train_target_x).cuda()\n",
    "                train_context_x = torch.stack(train_context_x).cuda()\n",
    "                    \n",
    "            # concatenate along a new dimension\n",
    "            train_target_y  = torch.stack(train_target_y).cuda()\n",
    "            train_context_y = torch.stack(train_context_y).cuda()\n",
    "            \n",
    "            # representation from deterministic encoder\n",
    "            rep = self.encoder.forward(train_context_x, train_context_y)\n",
    "            \n",
    "            # run decoder\n",
    "            mu, sigma, dist = self.decoder.forward(train_target_x, rep) \n",
    "            \n",
    "            # compute loss\n",
    "            loss = self.loss_fn(dist, train_target_y)\n",
    "            \n",
    "            # make predictions on the validation set\n",
    "            if epoch % self.pred_int == 0:\n",
    "                \n",
    "                # MAKE PREDICTION ON TRAIN TASKS -----------------------------\n",
    "                train_metrics = []\n",
    "                for true, pred in zip(train_target_y, mu):\n",
    "                    # compute metrics on train set\n",
    "                    tms_batch  = self.metrics.compute_metrics(true.cpu().data.numpy(),\n",
    "                                                              pred.cpu().data.numpy(),\n",
    "                                                              ['r2', 'mae', 'rmse', 'pearson', 'spearman',]\n",
    "                                                    )\n",
    "                    train_metrics.append(tms_batch)\n",
    "                \n",
    "                train_r2  = np.mean([t['r2'] for t in train_metrics])\n",
    "                train_mae = np.mean([t['mae'] for t in train_metrics]) \n",
    "\n",
    "        \n",
    "                \n",
    "                # MAKE PREDICTION ON VALIDATION TASKS -------------------------\n",
    "                task_ix_valid = np.random.randint(num_valid_tasks)\n",
    "                valid_task = valid_tasks[task_ix_valid]\n",
    "\n",
    "                valid_smiles = np.array(valid_task['smiles'])\n",
    "                valid_x = valid_task['X']\n",
    "                valid_y = valid_task['y']\n",
    "\n",
    "\n",
    "                num_target  = torch.randint(low=10, high=int(0.8*valid_x.shape[0]), size=(1,))\n",
    "                num_context = torch.randint(low=5, high=int(num_target), size=(1,))\n",
    "\n",
    "                indices = [np.random.permutation(valid_x.shape[0])[:num_target] for _ in range(self.batch_size)]\n",
    "                indices_context = [indices[_][:num_context] for _ in range(self.batch_size)]\n",
    "\n",
    "                valid_target_x  = [valid_x[indices[_], :] for _ in range(self.batch_size)]\n",
    "                valid_target_y  = [valid_y[indices[_], :] for _ in range(self.batch_size)]\n",
    "                \n",
    "                valid_target_smiles = [valid_smiles[indices[_]] for _ in range(self.batch_size)]\n",
    "                \n",
    "                valid_context_x = [valid_x[indices_context[_], :] for _ in range(self.batch_size)]\n",
    "                valid_context_y = [valid_y[indices_context[_], :] for _ in range(self.batch_size)]\n",
    "                \n",
    "                valid_context_smiles = [valid_smiles[indices_context[_]] for _ in range(self.batch_size)]\n",
    "                \n",
    "                \n",
    "                if self.use_mpnn:                 \n",
    "                    # generate the chemprop data loader thing --> context\n",
    "                    context_hs = []\n",
    "                    for batch_ix, (batch_smiles, batch_y) in enumerate(zip(valid_context_smiles, valid_context_y)):\n",
    "                        mol_dataset = get_data_from_deepchem(smiles_array=batch_smiles, targets_array=batch_y)\n",
    "                        graph, y = mol_dataset.batch_graph(), mol_dataset.targets()\n",
    "                        h = self.mpn(graph)\n",
    "                        context_hs.append(h)\n",
    "                    valid_context_x = torch.stack(context_hs).cuda()\n",
    "\n",
    "                    # generate the target hs\n",
    "                    target_hs = []\n",
    "                    for batch_ix, (batch_smiles, batch_y) in enumerate(zip(valid_target_smiles, valid_target_y)):\n",
    "                        mol_dataset = get_data_from_deepchem(smiles_array=batch_smiles, targets_array=batch_y)\n",
    "                        graph, y = mol_dataset.batch_graph(), mol_dataset.targets()\n",
    "                        h = self.mpn(graph)\n",
    "                        target_hs.append(h)\n",
    "                    valid_target_x = torch.stack(target_hs).cuda()\n",
    "                \n",
    "                else:\n",
    "                    valid_target_x  = torch.stack(valid_target_x).cuda()\n",
    "                    valid_context_x = torch.stack(valid_context_x).cuda()\n",
    "\n",
    "                # concatenate along a new dimension\n",
    "                valid_target_y  = torch.stack(valid_target_y).cuda()\n",
    "                valid_context_y = torch.stack(valid_context_y).cuda()\n",
    "                \n",
    "                 # representation from deterministic encoder\n",
    "                rep = self.encoder.forward(valid_context_x, valid_context_y)\n",
    "\n",
    "                # run decoder\n",
    "                mu, sigma, dist = self.decoder.forward(valid_target_x, rep) \n",
    "\n",
    "                # compute loss\n",
    "                valid_loss = self.loss_fn(dist, valid_target_y)\n",
    "                \n",
    "                # MAKE PREDICTION ON TRAIN TASKS -----------------------------\n",
    "                valid_metrics = []\n",
    "                for true, pred in zip(valid_target_y, mu):\n",
    "                    # compute metrics on train set\n",
    "                    vms_batch  = self.metrics.compute_metrics(true.cpu().data.numpy(),\n",
    "                                                              pred.cpu().data.numpy(),\n",
    "                                                              ['r2', 'mae', 'rmse', 'pearson', 'spearman',]\n",
    "                                                    )\n",
    "                    valid_metrics.append(vms_batch)\n",
    "                \n",
    "                valid_r2  = np.mean([t['r2'] for t in valid_metrics])\n",
    "                valid_mae = np.mean([t['mae'] for t in valid_metrics]) \n",
    "               \n",
    "                print(f'@@\\tEPOCH : {epoch}\\tTRAIN LOSS : {loss:.3f}\\tVALID LOSS : {valid_loss:.3f}\\tTRAIN R2 : {train_r2:.3f}\\tVALID R2 : {valid_r2:.3f}')\n",
    "        \n",
    "                \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        return None\n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict(self,\n",
    "                context_x, \n",
    "                context_y,\n",
    "                target_x,\n",
    "                num_samples:int=1,\n",
    "            ): \n",
    "        ''' Forward pass of the MPCNP\n",
    "        '''\n",
    "    \n",
    "        # return pred_mean, pred_std, pred_dist\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpcnp = MPCNP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpcnp.train(train_tasks, valid_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
